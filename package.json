{
    "name": "optimllm",
    "version": "1.0.0",
    "description": "Optimize LLM prompts to reduce tokens, save costs, and improve performance",
    "main": "dist/index.js",
    "types": "dist/index.d.ts",
    "files": [
      "dist",
      "README.md",
      "LICENSE"
    ],
    "scripts": {
      "build": "tsc",
      "test": "jest",
      "test:watch": "jest --watch",
      "test:coverage": "jest --coverage",
      "lint": "eslint src/**/*.ts",
      "lint:fix": "eslint src/**/*.ts --fix",
      "prepublishOnly": "npm run build && npm test",
      "prepare": "npm run build",
      "dev": "tsc --watch",
      "clean": "rm -rf dist"
    },
    "keywords": [
      "llm",
      "prompt",
      "optimization",
      "tokens",
      "ai",
      "gpt",
      "claude",
      "openai",
      "anthropic",
      "server-side",
      "nodejs",
      "typescript"
    ],
    "author": "Animesh (@theanimeshs)",
    "license": "MIT",
    "repository": {
      "type": "git",
      "url": "https://github.com/theanimeshs/optimllm.git"
    },
    "bugs": {
      "url": "https://github.com/theanimeshs/optimllm/issues"
    },
    "homepage": "https://github.com/theanimeshs/optimllm#readme",
    "engines": {
      "node": ">=16.0.0"
    },
    "devDependencies": {
      "@types/jest": "^29.5.12",
      "@types/node": "^20.10.0",
      "@typescript-eslint/eslint-plugin": "^6.15.0",
      "@typescript-eslint/parser": "^6.15.0",
      "eslint": "^8.56.0",
      "jest": "^29.7.0",
      "ts-jest": "^29.1.1",
      "ts-node": "^10.9.2",
      "typescript": "^5.3.3"
    },
    "dependencies": {
      "diff": "^8.0.2"
    }
  }
  